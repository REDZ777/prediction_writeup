unzip(zipfile = rawDataDFn, exdir = dataDir)
}
x_train <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/train/X_train.txt"))
y_train <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/train/Y_train.txt"))
s_train <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/train/subject_train.txt"))
x_test <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/test/X_test.txt"))
y_test <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/test/Y_test.txt"))
s_test <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/test/subject_test.txt"))
x_data <- rbind(x_train, x_test)
y_data <- rbind(y_train, y_test)
s_data <- rbind(s_train, s_test)
feature <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/features.txt"))
a_label <- read.table(paste(sep = "", dataDir, "/UCI HAR Dataset/activity_labels.txt"))
a_label[,2] <- as.character(a_label[,2])
selectedCols <- grep("-(mean|std).*", as.character(feature[,2]))
selectedColNames <- feature[selectedCols, 2]
selectedColNames <- gsub("-mean", "Mean", selectedColNames)
selectedColNames <- gsub("-std", "Std", selectedColNames)
selectedColNames <- gsub("[-()]", "", selectedColNames)
x_data <- x_data[selectedCols]
allData <- cbind(s_data, y_data, x_data)
colnames(allData) <- c("Subject", "Activity", selectedColNames)
allData$Activity <- factor(allData$Activity, levels = a_label[,1], labels = a_label[,2])
allData$Subject <- as.factor(allData$Subject)
meltedData <- melt(allData, id = c("Subject", "Activity"))
tidyData <- dcast(meltedData, Subject + Activity ~ variable, mean)
write.table(tidyData, "./tidy_dataset.txt", row.names = FALSE, quote = FALSE)
tidy_dataset
library(dplyr)
filename <- "Coursera_DS3_Final.zip"
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
x_test <- read.table("UCI HAR Dataset/test/x_test.txt", col.names = features$functions)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "both")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
x_train <- read.table("UCI HAR Dataset/train/x_train.txt", col.names = features$functions)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt", col.names = "both")
features <- read.table("UCI HAR Dataset/features.txt", col.names = c("n","functions"))
activities <- read.table("UCI HAR Dataset/activity_labels.txt", col.names = c("both", "activity"))
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
x_test <- read.table("UCI HAR Dataset/test/x_test.txt", col.names = features$functions)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "both")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
x_train <- read.table("UCI HAR Dataset/train/x_train.txt", col.names = features$functions)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt", col.names = "both")
x_merge <- rbind(x_train, x_test)
y_merge <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, Y, X)
x_merge <- rbind(x_train, x_test)
y_merge <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, y, x)
X <- rbind(x_train, x_test)
Y <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, Y, X)
x_merge <- rbind(x_train, x_test)
y_merge <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, y_merge, x_merge)
tidy_data <- Merged_Data %>% select(subject, both, contains("mean"), contains("std"))
tidy_data$both <- activities[tidy_data$both, 2]
names(tidy_data)<-gsub("-mean()", "Mean", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-std()", "STD", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-freq()", "Frequency", names(tidy_data), ignore.case = TRUE)
tidy_data_set <- tidy_data %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
#writing to tidy_data_set>txt
write.table(FinalData, "tidy_data_set.txt", row.name=FALSE)
tidy_data_set <- tidy_data %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
write.table(tidy_data_set, "tidy_data_set.txt", row.name=FALSE)
names(tidy_data)[2] = "activity"
names(tidy_data)<-gsub("-mean()", "Mean", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-std()", "STD", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-freq()", "Frequency", names(tidy_data), ignore.case = TRUE)
tidy_data_set <- tidy_data %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
write.table(tidy_data_set, "tidy_data_set.txt", row.name=FALSE)
library(dplyr)
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
library(dplyr)
filename <- "Coursera_DS3_Final.zip"
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
features <- read.table("UCI HAR Dataset/features.txt", col.names = c("n","functions"))
activities <- read.table("UCI HAR Dataset/activity_labels.txt", col.names = c("both", "activity"))
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
x_test <- read.table("UCI HAR Dataset/test/x_test.txt", col.names = features$functions)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "both")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
x_train <- read.table("UCI HAR Dataset/train/x_train.txt", col.names = features$functions)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt", col.names = "both")
x_merge <- rbind(x_train, x_test)
y_merge <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, y_merge, x_merge)
tidy_data <- Merged_Data %>% select(Merged_Data, both, contains("mean"), contains("std"))
tidy_data <- Merged_Data %>% select(subject, both, contains("mean"), contains("std"))
tidy_data$both <- activities[tidy_data$both, 2]
names(tidy_data)[2] = "activity"
names(tidy_data)<-gsub("-mean()", "Mean", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-std()", "STD", names(tidy_data), ignore.case = TRUE)
names(tidy_data)<-gsub("-freq()", "Frequency", names(tidy_data), ignore.case = TRUE)
tidy_data_set <- tidy_data %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
write.table(tidy_data_set, "tidy_data_set.txt", row.name=FALSE)
library(sqldf)
library(datasets)
## Select the data ranging from date: 01/02/2007 to 02/02/2007
householdpower <- read.csv.sql("household_power_consumption.txt", sql = "select * from file where Date in ('1/2/2007','2/2/2007')", sep=";", header=TRUE)
## Closing all connections to avoid getting connection errors
closeAllConnections()
## Changing date and time columns from character to POSIXct type and combining them into one
datetime <- as.POSIXct(paste(householdpower$Date, householdpower$Time),format = "%d/%m/%Y %H:%M:%S")
## Combining datetime column into householdpower data frame.
householdpower <- cbind(datetime, householdpower)
## Plotting Global Active Power in Kilowatts against datetime
with(householdpower, plot(datetime, Global_active_power, main = "Global Active Power", type = "l", xlab = "", ylab = "Global Active Power (Kilowatts)"))
## Copying the plot to PNG file
dev.copy(png, file="plot2.png")
dev.off()
library("data.table")
setwd("C:\Users\LiquidaTor\Desktop\household_power_consumption.txt")
#Reads in data from file then subsets data for specified dates
powerDT <- data.table::fread(input = "household_power_consumption.txt"
, na.strings="?"
)
# Prevents histogram from printing in scientific notation
powerDT[, Global_active_power := lapply(.SD, as.numeric), .SDcols = c("Global_active_power")]
# Change Date Column to Date Type
powerDT[, Date := lapply(.SD, as.Date, "%d/%m/%Y"), .SDcols = c("Date")]
# Filter Dates for 2007-02-01 and 2007-02-02
powerDT <- powerDT[(Date >= "2007-02-01") & (Date <= "2007-02-02")]
png("plot1.png", width=480, height=480)
## Plot 1
hist(powerDT[, Global_active_power], main="Global Active Power",
xlab="Global Active Power (kilowatts)", ylab="Frequency", col="Red")
dev.off()
zipFile <- "exdata%2Fdata%2Fhousehold_power_consumption.zip"
if(!file.exists("Data/household_power_consumption.txt")){
dataURL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
download.file(dataURL, zipFile, mode ="wb")
unzip(zipFile, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = "Data", unzip = "internal", setTimes = FALSE)
file.remove(zipFile)
}
power <- read.table("household_power_consumption.txt",skip=1,sep=";")
dirName <- 'Data
fileName = "household_power_consumption.txt"
fileNamePower <- file.path(dirName, fileName)
ata <- read.table(file = fileNamePower, header = TRUE, sep = ';')
# subset data set
data <- subset(data, Date == '1/2/2007' | Date == '2/2/2007')
# Convert some features to numeric features
ColNames <- names(data[3:9])
numericList <- c(ColNames)
data[, numericList] <- lapply(data[, numericList], function(x) as.numeric(as.character(x)))
# Merge date & time into single column
dateTime <- as.POSIXct(paste(data$Date, data$Time, sep = ";"), format = "%d/%m/%Y;%H:%M:%S")
data <- cbind("DateTime" = dateTime, data)
data$Date <- NULL
data$Time <- NULL
remove(dateTime)
library("data.table")
remove(dateTime)
zipFile <- "exdata%2Fdata%2Fhousehold_power_consumption.zip"
if(!file.exists("Data/household_power_consumption.txt")){
dataURL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
download.file(dataURL, zipFile, mode ="wb")
unzip(zipFile, files = NULL, list = FALSE, overwrite = TRUE, junkpaths = FALSE, exdir = "Data", unzip = "internal", setTimes = FALSE)
file.remove(zipFile)
}
dirName <- 'Data'
fileName = "household_power_consumption.txt"
fileNamePower <- file.path(dirName, fileName)
data <- read.table(file = fileNamePower, header = TRUE, sep = ';')
data <- subset(data, Date == '1/2/2007' | Date == '2/2/2007')
ColNames <- names(data[3:9])
numericList <- c(ColNames)
data[, numericList] <- lapply(data[, numericList], function(x) as.numeric(as.character(x)))
dateTime <- as.POSIXct(paste(data$Date, data$Time, sep = ";"), format = "%d/%m/%Y;%H:%M:%S")
data <- cbind("DateTime" = dateTime, data)
data$Date <- NULL
data$Time <- NULL
remove(dateTime)
png(filename = "plot1.png", width = 480, height = 480, units = "px", bg = "transparent")
hist(data$Global_active_power, col = "red", main = "Global Active Power", xlab = "Global Active Power (kilowatts)")
dev.off()
png(filename = "plot1.png", width = 480, height = 480, units = "px", bg = "transparent")
> hist(data$Global_active_power, col = "red", main = "Global Active Power", xlab = "Global Active Power (kilowatts)")
png(filename = "plot1.png", width = 480, height = 480, units = "px", bg = "transparent")
hist(data$Global_active_power, col = "red", main = "Global Active Power", xlab = "Global Active Power (kilowatts)")
dev.off()
setwd("C:/Users/Akash Gupta/Desktop/Books/R wrangling/Exploratory data analysis Coursera")
data_full <- read.csv("household_power_consumption.txt", header=T, sep=';', na.strings="?",
nrows=2075259, check.names=F, stringsAsFactors=F, comment.char="", quote='\"')
dataFile <- "./data/household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datetime <- strptime(paste(subSetData$Date, subSetData$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot2.png", width=480, height=480)
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power (kilowatts)")
dev.off()
dev.off()
dataFile <- "./data/household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
#str(subSetData)
datetime <- strptime(paste(subSetData$Date, subSetData$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot2.png", width=480, height=480)
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power (kilowatts)")
dev.off()
View(data)
View(datetime)
View(subSetData)
dataFile <- "./data/household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
#str(subSetData)
datetime <- strptime(paste(subSetData$Date, subSetData$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot2.png", width=480, height=480)
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power (kilowatts)")
dev.off()
dataFile <- "./data/household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datetime <- strptime(paste(subSetData$Date, subSetData$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot2.png", width=480, height=480)
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power (kilowatts)")
dev.off
dev.off()
library(DT)
library("data.table")
dataFile <- "./data/household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
#str(subSetData)
datetime <- strptime(paste(subSetData$Date, subSetData$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(subSetData$Global_active_power)
subMetering1 <- as.numeric(subSetData$Sub_metering_1)
subMetering2 <- as.numeric(subSetData$Sub_metering_2)
subMetering3 <- as.numeric(subSetData$Sub_metering_3)
png("plot3.png", width=480, height=480)
plot(datetime, subMetering1, type="l", ylab="Energy Submetering", xlab="")
lines(datetime, subMetering2, type="l", col="red")
lines(datetime, subMetering3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, lwd=2.5, col=c("black", "red", "blue"))
dev.off()
setwd("C:/Users/LiquidaTor/Desktop/household_power_consumption.txt")
data_full <- read.csv("household_power_consumption.txt", header=T, sep=';', na.strings="?",
nrows=2075259, check.names=F, stringsAsFactors=F, comment.char="", quote='\"')
data1 <- subset(data_full, Date %in% c("1/2/2007","2/2/2007"))
data1$Date <- as.Date(data1$Date, format="%d/%m/%Y")
hist(data1$Global_active_power, main="Global Active Power",
xlab="Global Active Power (kilowatts)", ylab="Frequency", col="Red")
library("data.table")
path <- getwd()
download.file(url = "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
, destfile = paste(path, "dataFiles.zip", sep = "/"))
unzip(zipfile = "dataFiles.zip")
SCC <- data.table::as.data.table(x = readRDS(file = "Source_Classification_Code.rds"))
NEI <- data.table::as.data.table(x = readRDS(file = "summarySCC_PM25.rds"))
# Prevents histogram from printing in scientific notation
NEI[, Emissions := lapply(.SD, as.numeric), .SDcols = c("Emissions")]
totalNEI <- NEI[, lapply(.SD, sum, na.rm = TRUE), .SDcols = c("Emissions"), by = year]
barplot(totalNEI[, Emissions]
, names = totalNEI[, year]
, xlab = "Years", ylab = "Emissions"
, main = "Emissions over the Years")
library(plyr)
library(dplyr)
library(ggplot2)
options(scipen=999)
## This first line will likely take a few seconds. Be patient!
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
df <- subset(SCC, select = c("SCC", "Short.Name"))
NEI <- merge(NEI, df, by.x="SCC", by.y="SCC", all=TRUE)
rm(SCC)
## Q1
# Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
#         Using the base plotting system, make a plot showing the total PM2.5 emission from all sources
#         for each of the years 1999, 2002, 2005, and 2008.
# Data prep
plot1 <- aggregate(Emissions ~ year, NEI, sum)
png(file = "plot1.png")
# Plot the chart
plot((Emissions / 1000) ~ year,
data = plot1,
type = "l",
#ylim = c(min(df1[ ,-1]), max(df1[ ,-1])),
xlab = "Year",
ylab = "Total emissions (/1000)",
main = "Total US PM2.5 Emissions",
xaxt="n")
axis(side=1, at=c("1999", "2002", "2005", "2008"))
# Save the file.
dev.off()
View(plot1)
# Save the file.
dev.off()
library("data.table")
path <- getwd()
download.file(url = "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
, destfile = paste(path, "dataFiles.zip", sep = "/"))
unzip(zipfile = "dataFiles.zip")
SCC <- data.table::as.data.table(x = readRDS(file = "Source_Classification_Code.rds"))
NEI <- data.table::as.data.table(x = readRDS(file = "summarySCC_PM25.rds"))
# Prevents histogram from printing in scientific notation
NEI[, Emissions := lapply(.SD, as.numeric), .SDcols = c("Emissions")]
totalNEI <- NEI[, lapply(.SD, sum, na.rm = TRUE), .SDcols = c("Emissions"), by = year]
barplot(totalNEI[, Emissions]
, names = totalNEI[, year]
, xlab = "Years", ylab = "Emissions"
, main = "Emissions over the Years")
NEI <- readRDS("E:/Exploratory-Data-Analysis/Week 4/summarySCC_PM25.rds")
SCC <- readRDS("E:/Exploratory-Data-Analysis/Week 4/Source_Classification_Code.rds")
# Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
# Using the base plotting system, make a plot showing the total PM2.5 emission from all sources
# for each of the years 1999, 2002, 2005, and 2008.
aggregatedTotalByYear <- aggregate(Emissions ~ year, NEI, sum)
# Saving to file
barplot(height=aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="years", ylab=expression('total PM'[2.5]*' emission'),main=expression('Total PM'[2.5]*' emissions at various years'))
dev.copy(png, file="plot1.png", height=640, width=640)
dev.off()
NEI <- readRDS("E:/Exploratory-Data-Analysis/Week 4/summarySCC_PM25.rds")
SCC <- readRDS("E:/Exploratory-Data-Analysis/Week 4/Source_Classification_Code.rds")
# Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
# Using the base plotting system, make a plot showing the total PM2.5 emission from all sources
# for each of the years 1999, 2002, 2005, and 2008.
aggregatedTotalByYear <- aggregate(Emissions ~ year, NEI, sum)
# Saving to file
barplot(height=aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="years", ylab=expression('total PM'[2.5]*' emission'),main=expression('Total PM'[2.5]*' emissions at various years'))
dev.copy(png, file="plot1.png", height=640, width=640)
dev.off()
NEI <- readRDS("E:/Exploratory-Data-Analysis/Week 4/summarySCC_PM25.rds")
SCC <- readRDS("E:/Exploratory-Data-Analysis/Week 4/Source_Classification_Code.rds")
# Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
# Using the base plotting system, make a plot showing the total PM2.5 emission from all sources
# for each of the years 1999, 2002, 2005, and 2008.
aggregatedTotalByYear <- aggregate(Emissions ~ year, NEI, sum)
# Saving to file
barplot(height=aggregatedTotalByYear$Emissions, names.arg=aggregatedTotalByYear$year, xlab="years", ylab=expression('total PM'[2.5]*' emission'),main=expression('Total PM'[2.5]*' emissions at various years'))
dev.copy(png, file="plot1.png", height=640, width=640)
dev.off()
library("data.table")
library("ggplot2")
library(DT)
library("data.table")
library("ggplot2")
install.packages("knitr")
library(knitr)
install.packages("knitr")
library("knitr", lib.loc="~/R/win-library/4.0")
install.packages("data.table")
library("data.table", lib.loc="~/R/win-library/4.0")
library("knitr", lib.loc="~/R/win-library/4.0")
install.packages("ggplot2")
library("ggplot2", lib.loc="~/R/win-library/4.0")
library("knitr", lib.loc="~/R/win-library/4.0")
library("data.table", lib.loc="~/R/win-library/4.0")
library("knitr", lib.loc="~/R/win-library/4.0")
library("knitr", lib.loc="~/R/win-library/4.0")
knitr::opts_chunk$set(echo = TRUE)
library("data.table")
library("ggplot2")
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileUrl, destfile = paste0("/Users/mgalarny/Desktop", '/repdata%2Fdata%2FStormData.csv.bz2'))
library("data.table")
library("ggplot2")
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileUrl, destfile = paste0("/Users/mgalarny/Desktop", '/repdata%2Fdata%2FStormData.csv.bz2'))
library("data.table")
library("ggplot2")
StormData <- read.csv("C:/Users/LiquidaTor/Desktop/StormData.csv")
stormDT <- as.data.table(stormDF)
library("data.table")
library("ggplot2")
StormDF <- read.csv("C:/Users/LiquidaTor/Desktop/StormData.csv")
stormDT <- as.data.table(stormDF)
library("data.table")
library("ggplot2")
StormDT <- read.csv("C:/Users/LiquidaTor/Desktop/StormData.csv")
stormDT <- as.data.table(stormDF)
library("data.table")
library("ggplot2")
StormDF <- read.csv("C:/Users/LiquidaTor/Desktop/StormData.csv")
stormDT <- as.data.table(stormDF)
install.packages("plyr")
install.packages("gridExtra")
library("plyr", lib.loc="~/R/win-library/4.0")
library(ggplot2)
library(datasets)
library(datasets)
library(gridExtra)
data(ToothGrowth)
dim(ToothGrowth)
head(ToothGrowth)
str(ToothGrowth)
summary(ToothGrowth)
plot_right <-ggplot(ToothGrowth,aes(len,fill=supp)) +
geom_density(alpha=.5) +coord_flip() +
scale_fill_manual(values=c("orange","purple")) +
theme(legend.position="none") +
labs(title="Density Plot",y="Density",x="Tooth Length")
grid.arrange(scatter, plot_right, ncol=2, nrow=1, widths=c(4, 2))
table(ToothGrowth$supp,ToothGrowth$dose)
t.test(len ~ supp, paired = F, var.equal = F, data = ToothGrowth)
t.test(len ~ supp, paired = F, var.equal = F, data = ToothGrowth)
ToothGrowth.doses_0.5_1.0 <- subset (ToothGrowth, dose %in% c(0.5, 1.0))
ToothGrowth.doses_0.5_2.0 <- subset (ToothGrowth, dose %in% c(0.5, 2.0))
ToothGrowth.doses_1.0_2.0 <- subset (ToothGrowth, dose %in% c(1.0, 2.0))
Dose5_10 <- subset(ToothGrowth, dose %in% c(0.5, 1.0))
Dose5_20 <- subset(ToothGrowth, dose %in% c(0.5, 2.0))
Dose10_20 <- subset(ToothGrowth, dose %in% c(1.0, 2.0))
t.test(len ~ dose, paired = F, var.equal = F, data = Dose5_10)
t.test(len ~ dose, paired = F, var.equal = F, data = Dose5_20
t.test(len ~ dose, paired = F, var.equal = F, data = Dose_10_20)
t.test(len ~ dose, paired = F, var.equal = F, data = Dose_10_20)
t.test(len ~ dose, paired = F, var.equal = F, data = Dose10_20)
install.packages("caret")
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
library(knitr)
install.packages("knitLatex")
library(knitLatex)
install.packages("knitr")
install.packages("knitLatex")
library(knitLatex)
library(knitr)
library(ggplot2)
install.packages("tinytex")
library(tinytex)
install.packages("leaflet")
install.packages("leaflet")
library(leaflet)
knitr::opts_chunk$set(echo = TRUE)
place <- c("16 Buckingham Drive", "Eastampton Community School", "Rancocas Valley Regional High School", "Buttonwood Park", "Rutgers University", "University of California, Los Anglees", "10941 Strathmore Drive", "Aurora", "Coffee Bean", "many dollars spent, many books unread, much music heard", "St. Agnes Hospital", "Talvandi Arain", "Sialkot, Punjab", "Dharamsala, Himachal Pradesh", "Magnolia Hotel", "Wu Tang Klang", "Shrine of Bullhe Shah", "St. Joseph Hospital", "Lahore, Punjab", "Ratajoa (Pool of Blood)" )
place_links <- c("<a href='https://www.gps-coordinates.net/street-view/@39.992445,-74.765458,h182,p5,z1'>Home</a>", "<a href='http://www.eastampton.k12.nj.us/'>Primary</a>", "<a href='http://rvrhs.com/'>High School</a>", "<a href='https://www.youtube.com/watch?v=WH_PC4UOoY4'>Tennis</a>", "<a href='http://newbrunswick.rutgers.edu/?utm_source=rutgers.edu&utm_medium=web&utm_campaign=uwide_sliver'>College</a>", "<a href='http://socialsciences.ucla.edu/departments/'>UCLA</a>", "<a href='https://en.wikipedia.org/wiki/Bhavacakra'>Westwood</a>", "<a href='http://cherrycreekschools.org/Pages/default.aspx'>Centennial</a>", "<a href='https://psychcentral.com/blog/archives/2012/04/15/caffeines-effects-on-your-thinking/'>many cups of joe</a>", "<a href='https://shop.uclastore.com/c-318-bookzone.aspx'>many dollars spent, many books unread</a>", "<a href='http://www.stagnes.org/150/'>where it all began</a>", "<a href='https://en.wikipedia.org/wiki/Partition_of_India'>daadkay dee praanee pind</a>", "<a href='https://en.wikipedia.org/wiki/Sialkot'>Ami day naandkay</a>", "<a href='https://www.youtube.com/watch?v=nWY0Tyhu9MM'>Madhyamaka</a>", "<a href='http://www.starwoodhotels.com/gx/property/overview/index.html?propertyID=4703&SWAQ=958P'>The Special Day</a>", "<a href='https://en.wikipedia.org/wiki/Klang_(city)'>Klang</a>", "<a href='https://www.youtube.com/watch?v=B-pTz8ZM0nw'>Bullhe Shah</a>", "<a href='https://www.sclhealth.org/locations/saint-joseph-hospital/'>My Seeds</a>", "<a href='https://en.wikipedia.org/wiki/Lahore'>Lahore</a>", "<a href='http://press.princeton.edu/titles/4250.html'>Pind</a>")
lat <- c(39.9921999, 39.99891909999999, 40.0024695, 39.99760750000001, 40.5203204, 34.068921,
34.0672062, 39.615245, 39.615245, 34.0627396, 39.9260163, 31.5188331, 31.5188331,
32.5179603, 32.21904200000001, 3.044917, 31.12107223150165, 39.7464498, 31.4054167, 31.1914511)
lng <- c(-74.76549999999997, -74.75457560000001, -74.7829026, -74.7633318, -74.43591049999998,
-118.44518110000001, -118.45007800000002, -104.79553599999997, -118.44504139999998, -118.44456500000001,
-75.1697964, 75.74659750000001, 74.50091680000003, 76.32340369999997, -104.99235140000002,
101.44556209999996, 74.44769382476807, -104.9715971, 74.16363130000002, 74.05791850000003)
df <- data.frame(place, place_links, lat, lng)
library(leaflet)
df %>%
leaflet() %>%
addTiles() %>%
addMarkers(lat=lat, lng=lng, popup=place_links, clusterOptions=markerClusterOptions)
knitr::opts_chunk$set(echo = TRUE)
place <- c("16 Buckingham Drive", "Eastampton Community School", "Rancocas Valley Regional High School", "Buttonwood Park", "Rutgers University", "University of California, Los Anglees", "10941 Strathmore Drive", "Aurora", "Coffee Bean", "many dollars spent, many books unread, much music heard", "St. Agnes Hospital", "Talvandi Arain", "Sialkot, Punjab", "Dharamsala, Himachal Pradesh", "Magnolia Hotel", "Wu Tang Klang", "Shrine of Bullhe Shah", "St. Joseph Hospital", "Lahore, Punjab", "Ratajoa (Pool of Blood)" )
lat <- c(39.9921999, 39.99891909999999, 40.0024695, 39.99760750000001, 40.5203204, 34.068921,
34.0672062, 39.615245, 39.615245, 34.0627396, 39.9260163, 31.5188331, 31.5188331,
32.5179603, 32.21904200000001, 3.044917, 31.12107223150165, 39.7464498, 31.4054167, 31.1914511)
lng <- c(-74.76549999999997, -74.75457560000001, -74.7829026, -74.7633318, -74.43591049999998,
-118.44518110000001, -118.45007800000002, -104.79553599999997, -118.44504139999998, -118.44456500000001,
-75.1697964, 75.74659750000001, 74.50091680000003, 76.32340369999997, -104.99235140000002,
101.44556209999996, 74.44769382476807, -104.9715971, 74.16363130000002, 74.05791850000003)
df <- data.frame(place, place_links, lat, lng)
library(leaflet)
df %>%
leaflet() %>%
addTiles() %>%
addMarkers(lat=lat, lng=lng, popup=place_links, clusterOptions=markerClusterOptions)
data()
data(sleep)
install.packages("shiny")
knitr::opts_chunk$set(echo = TRUE)
data("airquality")
data("airquality")
?airquality
install.packages("randomForest")
install.packages('e1071', dependencies=TRUE)
install.packages("caret")
knitr::opts_chunk$set(echo = TRUE)
controlXGB <- trainControl(method="cv", 5, allowParallel = TRUE)
setwd("~/GitHub")
